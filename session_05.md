# Demystifying Terms Data Science, Machine Learning, Artificial Intelligence
## Artificial Intelligence
Artificial intelligence (AI) is the ability of machines to learn, think, and perform tasks, especially computer systems. AI uses technologies like machine learning and neural networks to analyze data, make decisions, and more. 
Types of AI
1) Machine learning: A subset of AI that uses algorithms to learn from data and improve over time 
2) Deep learning: A subset of machine learning that uses neural networks to make predictions 
3) Generative AI: A type of AI that can create new content like text, images, or videos based on user prompts 
4) Natural language processing: A type of AI that enables computers to understand and use human language
   
## Artificial General Intelligence
Artificial general intelligence (AGI) is a hypothetical machine intelligence that can learn and perform any intellectual task a human can. AGI is also known as strong AI or deep AI. 

How AGI might work
1) Learn human behavior: AGI can learn human behavior and understand consciousness. 
2) Transfer knowledge: AGI can transfer knowledge and skills learned in one domain to another. 
3) Common sense: AGI has a vast knowledge of the world, including facts, relationships, and social norms. 
4) Social and emotional engagement: AGI can recognize and understand emotions, including facial expressions, body language, and tone of voice.
   
Potential uses of AGI 
1) Assisting healthcare workers
2) Making recommendations for movies, music, and books
3) Contributing to the development of new products and industries
4) Increasing the abundance of resources
5) Turbocharging the global economy
6) Discovering new scientific knowledge

## History of Artificial Intelligence
A survey of important events and people in the field of artificial intelligence (AI) from the early work of British logician Alan Turing in the 1930s to advancements at the turn of the 21st century. AI is the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience. For modern developments in AI, see artificial intelligence.

The earliest substantial work in the field of artificial intelligence was done in the mid-20th century by the British logician and computer pioneer Alan Mathison Turing. In 1935 Turing described an abstract computing machine consisting of a limitless memory and a scanner that moves back and forth through the memory, symbol by symbol, reading what it finds and writing further symbols. The actions of the scanner are dictated by a program of instructions that also is stored in the memory in the form of symbols. This is Turing’s stored-program concept, and implicit in it is the possibility of the machine operating on, and so modifying or improving, its own program. Turing’s conception is now known simply as the universal Turing machine. All modern computers are in essence universal Turing machines.

Turing gave quite possibly the earliest public lecture (London, 1947) to mention computer intelligence, saying, “What we want is a machine that can learn from experience,” and that the “possibility of letting the machine alter its own instructions provides the mechanism for this.” In 1948 he introduced many of the central concepts of AI in a report entitled “Intelligent Machinery.” However, Turing did not publish this paper, and many of his ideas were later reinvented by others. For instance, one of Turing’s original ideas was to train a network of artificial neurons to perform specific tasks, an approach described in the section Connectionism.

### Perceptron. 
Perceptron was introduced by Frank Rosenblatt in 1957. He proposed a Perceptron learning rule based on the original MCP neuron. A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.
![image](https://github.com/user-attachments/assets/b10a89bd-e5ed-45dd-8f02-616ba3f2bf9d)


### Backpropagation
Backpropagation is a machine learning technique essential to the optimization of artificial neural networks. It facilitates the use of gradient descent algorithms to update network weights, which is how the deep learning models driving modern artificial intelligence (AI) “learn.”

It’s essential to the use of supervised learning, semi-supervised learning or self-supervised learning to train neural networks.

### AI Winter
The "AI Winter": The field faced funding cuts and diminished enthusiasm during the 1970s and 1980s, known as the "AI Winter," due to the inability of AI systems to deliver on the high expectations set earlier.

### DARPA Grand Challenge 2005
The DARPA Grand Challenge 2005 was a pivotal event in the history of autonomous vehicles and artificial intelligence. 
Organized by the Defense Advanced Research Projects Agency (DARPA), the competition aimed to advance the development of self-driving cars. 
It marked a significant step forward in autonomous vehicle technology and showcased the potential of AI and robotics in real-world applications.
Background
The DARPA Grand Challenge was created to encourage research and development in autonomous vehicles, with the goal of creating military robots that could navigate dangerous terrain without human intervention. The competition was designed to push the boundaries of technology and innovation by setting a challenging goal for robotic systems.

The Challenge
The 2005 DARPA Grand Challenge required autonomous vehicles to navigate a 132-mile course across the Mojave Desert in California, filled with obstacles such as hills, sharp turns, and narrow roads. The goal was to complete the race in the shortest time possible, with no human intervention.
The course was designed to be extremely difficult, with both technical and environmental challenges. The vehicles had to navigate through sand, rocks, and other terrain features, all while avoiding other obstacles, without any human control.

Key Takeaways and Impact
Technological Advancements: The 2005 challenge pushed the boundaries of AI and robotics, advancing technologies like autonomous navigation, real-time decision-making, and sensor-based systems.

Increased Interest in Autonomous Vehicles: The success of vehicles like Stanley brought widespread attention to the potential of self-driving cars, especially in terms of safety, logistics, and defense applications.

Inspiration for Future Research: The Grand Challenge was a major stepping stone for research in autonomous driving. It sparked further innovation, with companies like Google (now Waymo) and others focusing on developing self-driving cars.

Influence on DARPA's Subsequent Challenges: The DARPA Urban Challenge of 2007, which featured a more complex urban driving environment, was a follow-up to the 2005 event, demonstrating the growing sophistication of autonomous vehicles.


### ImageNet 2012
ImageNet is a large-scale image database created to support research in visual recognition and machine learning. It contains millions of labeled images that are classified into thousands of categories (e.g., animals, vehicles, objects, etc.). Researchers use ImageNet to train and test algorithms for image classification, object detection, and other visual recognition tasks.

### 2024 Nobel Prize in Physics

The 2024 Nobel Prize in Physics was awarded to John J. Hopfield and Geoffrey E. Hinton for their foundational discoveries and inventions that enable machine learning with artificial neural networks. 
NOBELPRIZE.ORG
John J. Hopfield is an American physicist and emeritus professor at Princeton University. He is renowned for his work on associative neural networks, particularly the Hopfield network, which has been instrumental in pattern recognition and data storage. 
EN.WIKIPEDIA.ORG
Geoffrey E. Hinton is a British-Canadian computer scientist and professor emeritus at the University of Toronto. Often referred to as the "godfather of AI," Hinton has made significant contributions to the development of deep learning algorithms, particularly in the training of deep neural networks. 
BUSINESSINSIDER.COM

Their pioneering work has been instrumental in the development of artificial intelligence technologies that are now integral to various applications, including image and speech recognition, natural language processing, and autonomous systems.


![image](https://github.com/user-attachments/assets/a9adaabf-2d16-4747-91b9-6790f9fd9429) ![image](https://github.com/user-attachments/assets/36106dae-59ef-4ad8-8e18-ed227e1bb345)



  
### Deepseek
![image](https://github.com/user-attachments/assets/55023353-adb3-425d-a243-a9b351e4897e)
* A chinese AI firm
* On Jan. 20, 2025, DeepSeek released its R1 LLM at a fraction of the cost that other vendors incurred in their own developments.
* DeepSeek is also providing its R1 models under an open source license, enabling free use.
* DeepSeek focuses on developing open source, meaning they are freely available for anyone to use, modify, and distribute.
* 
## Key Deciding Factors of Growth of AI
1. Huge amount of data (explosion of data)
2. Computing power
3. Algorithmic improvements

   
## Data Science, Machine Learning and Artificial Intelligence
## Data Science Application Domains
## Correlation Vs. Causation
## Ethics in AI
1. Privacy: Ensure there is no task of personal confidential information.
2. Accountability:
3. Safety: Control over what data is being used and
4. Transparency: Ensure compliance with human moralities.
5. Respect for human values: Ensuring sensitivity to different cultural norms and values.
6. Fairness: No discrimination based on gender, race, caste or cred 
